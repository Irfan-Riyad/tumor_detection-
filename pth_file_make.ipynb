{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRV8bp8KD6gJ",
        "outputId": "e83fb1fd-ffca-4ecf-ccf7-d87af8ed2d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“Œ Step 1: Install dependencies\n",
        "!pip install torch torchvision scikit-learn tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CELL 2: DOWNLOAD AND PREPARE DATASET\n",
        "# ==============================================================================\n",
        "# --- Download from Kaggle ---\n",
        "import kagglehub\n",
        "import shutil # Import shutil module\n",
        "print(\"Downloading dataset from Kaggle Hub...\")\n",
        "path = kagglehub.dataset_download(\"mrnotalent/braint\")\n",
        "print(f\"Path to dataset files: {path}\")\n",
        "\n",
        "# --- Copy to a writable directory ---\n",
        "# This is necessary as the Kaggle input directory is read-only\n",
        "src = path\n",
        "dst = '/content/braint_original'\n",
        "shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "print(f\"Dataset copied to {dst}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPHhWNIELLsa",
        "outputId": "caa7b591-a294-4c3d-8c53-aba057a65e3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from Kaggle Hub...\n",
            "Path to dataset files: /kaggle/input/braint\n",
            "Dataset copied to /content/braint_original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 2: Import libraries\n",
        "import os, json, random\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split, DataLoader, Subset\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "6ekrpLe3EF-v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 3: Reproducibility\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "m8BJfkjtEIbZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 4: Data transforms\n",
        "def build_transforms(image_size: int = 224, grayscale_to_rgb: bool = True):\n",
        "    tfms_train, tfms_val = [], []\n",
        "\n",
        "    if grayscale_to_rgb:\n",
        "        tfms_train.append(transforms.Grayscale(num_output_channels=3))\n",
        "        tfms_val.append(transforms.Grayscale(num_output_channels=3))\n",
        "\n",
        "    tfms_train += [\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        "    tfms_val += [\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        "    return transforms.Compose(tfms_train), transforms.Compose(tfms_val)\n"
      ],
      "metadata": {
        "id": "Yyx09Y48EMG1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 5: Build datasets (automatic train/val split if no folders)\n",
        "def build_datasets(root_dir: str, image_size=224, grayscale_to_rgb=True, val_split=0.15):\n",
        "    root = Path(root_dir)\n",
        "    train_dir, val_dir = root / \"train\", root / \"val\"\n",
        "    has_splits = train_dir.exists() and val_dir.exists()\n",
        "    tfm_train, tfm_val = build_transforms(image_size, grayscale_to_rgb)\n",
        "\n",
        "    if has_splits:\n",
        "        train_ds = datasets.ImageFolder(train_dir, transform=tfm_train)\n",
        "        val_ds = datasets.ImageFolder(val_dir, transform=tfm_val)\n",
        "    else:\n",
        "        full_ds = datasets.ImageFolder(root, transform=tfm_train)\n",
        "        n_val = int(val_split * len(full_ds))\n",
        "        n_train = len(full_ds) - n_val\n",
        "        train_idx, val_idx = random_split(range(len(full_ds)), [n_train, n_val], generator=torch.Generator().manual_seed(42))\n",
        "        train_ds = Subset(full_ds, train_idx)\n",
        "        val_base = datasets.ImageFolder(root, transform=tfm_val)\n",
        "        val_ds = Subset(val_base, val_idx)\n",
        "        train_ds.dataset.class_to_idx = full_ds.class_to_idx\n",
        "        val_ds.dataset.class_to_idx = full_ds.class_to_idx\n",
        "    return train_ds, val_ds\n"
      ],
      "metadata": {
        "id": "endDHHW8EQya"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 6: Build ResNet50 model\n",
        "def build_model(num_classes: int, pretrained=True):\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "    model = models.resnet50(weights=weights)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "j5WmlfolEShz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 7: Training & validation loop\n",
        "def step_epoch(model, loader, criterion, optimizer=None, device=\"cpu\"):\n",
        "    is_train = optimizer is not None\n",
        "    model.train(is_train)\n",
        "\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for imgs, labels in tqdm(loader, disable=False):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        correct += (logits.argmax(1) == labels).sum().item()\n",
        "        total += imgs.size(0)\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "GySfQQlWEUDV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 8: Load dataset\n",
        "data_dir = \"/kaggle/input/braint\"\n",
        "train_ds, val_ds = build_datasets(data_dir, image_size=224, grayscale_to_rgb=True)\n",
        "\n",
        "class_names = train_ds.dataset.classes if hasattr(train_ds, \"dataset\") else train_ds.classes\n",
        "print(f\"Detected {len(class_names)} classes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4ii3jeRK5cl",
        "outputId": "968b40f7-9be6-407a-ff7f-834f9ce13c9c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 44 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 9: DataLoaders\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "hFirewyXK6im"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 10: Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = build_model(num_classes=len(class_names), pretrained=True).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwucT5s3K9A8",
        "outputId": "8759f29a-89f5-4abd-cbd5-1d16e492efa9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 154MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 11: Train the model\n",
        "best_acc, best_path = 0.0, \"resnet50_44cls_best.pth\"\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "    tr_loss, tr_acc = step_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    va_loss, va_acc = step_epoch(model, val_loader, criterion, None, device)\n",
        "    print(f\"Train: loss={tr_loss:.4f}, acc={tr_acc:.4f} | Val: loss={va_loss:.4f}, acc={va_acc:.4f}\")\n",
        "    scheduler.step(va_acc)\n",
        "    if va_acc > best_acc:\n",
        "        best_acc = va_acc\n",
        "        torch.save({\n",
        "            \"arch\": \"resnet50\",\n",
        "            \"num_classes\": len(class_names),\n",
        "            \"classes\": class_names,\n",
        "            \"state_dict\": model.state_dict()\n",
        "        }, best_path)\n",
        "        print(f\"âœ… Saved best model to {best_path} (val_acc={best_acc:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzgksteAK_sa",
        "outputId": "7eb70932-ab52-41cf-aeb2-12c37211f7a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:37<00:00,  5.46it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:19<00:00,  7.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=3.3745, acc=0.0972 | Val: loss=2.9406, acc=0.1602\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.1602)\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:37<00:00,  5.48it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:19<00:00,  7.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=2.6053, acc=0.2464 | Val: loss=2.4442, acc=0.3055\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.3055)\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:37<00:00,  5.47it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:19<00:00,  7.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=2.0276, acc=0.3909 | Val: loss=1.8677, acc=0.4357\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.4357)\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:37<00:00,  5.48it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:19<00:00,  7.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=1.5936, acc=0.5176 | Val: loss=1.4309, acc=0.5491\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.5491)\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:37<00:00,  5.48it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:18<00:00,  8.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=1.3019, acc=0.5980 | Val: loss=1.2534, acc=0.6062\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.6062)\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:37<00:00,  5.49it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:18<00:00,  8.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=1.0714, acc=0.6650 | Val: loss=0.9839, acc=0.6953\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.6953)\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:37<00:00,  5.48it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:18<00:00,  8.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.8856, acc=0.7241 | Val: loss=0.7877, acc=0.7515\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.7515)\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:37<00:00,  5.49it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:18<00:00,  8.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.7461, acc=0.7638 | Val: loss=0.7411, acc=0.7717\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.7717)\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:36<00:00,  5.50it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:18<00:00,  8.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.6411, acc=0.7947 | Val: loss=0.6132, acc=0.8045\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.8045)\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 863/863 [02:36<00:00,  5.51it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153/153 [00:18<00:00,  8.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.5413, acc=0.8260 | Val: loss=0.6165, acc=0.8119\n",
            "âœ… Saved best model to resnet50_44cls_best.pth (val_acc=0.8119)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ Step 12: Save classes.txt for Streamlit app\n",
        "with open(\"classes.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(class_names))\n",
        "print(\"Saved classes.txt with class labels.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_-4IMQILFPl",
        "outputId": "fce4dfdf-f287-466e-cab9-884518b4db9f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved classes.txt with class labels.\n"
          ]
        }
      ]
    }
  ]
}